{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, I am going to code a 3 layer (input, hidden, output), customizable neural network from scratch - including back propagation. It will be a fully-connected binary classification neural network to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel:\n",
    "    def __init__(self, input_dim, hidden_dim, learning_rate=0.01, regularization=5):\n",
    "        self.weights = dict()\n",
    "        self.biases = dict()\n",
    "        \n",
    "        self.weights['L1'] = np.random.rand(hidden_dim, input_dim)\n",
    "        self.weights['L2'] = np.random.rand(1, hidden_dim)\n",
    "        \n",
    "        self.biases['L1'] = np.random.rand(hidden_dim, 1)\n",
    "        self.biases['L2'] = np.random.rand(1,1)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "        \n",
    "        next;\n",
    "        \n",
    "    def sigmoid(self, data):\n",
    "#         bigger_data = np.array(data,dtype=np.float128)\n",
    "        data = np.clip(data,a_min=-100, a_max=100)\n",
    "        if np.sum(np.isnan(data)) > 0:\n",
    "            print('nan:',np.sum(np.isnan(data)))\n",
    "            print(data)\n",
    "        return 1/(1+np.exp(-data))\n",
    "    \n",
    "    def sigmoidPrime(self, data):\n",
    "        oz = self.sigmoid(data)\n",
    "        return oz * (1-oz)\n",
    "    \n",
    "    def crossEntropyPrime(self, a2, target):\n",
    "        epsilon = 10e-7\n",
    "        return (-target+a2)/(a2*(1-a2)+epsilon)\n",
    "    \n",
    "    def crossEntropyError(self, a2, target):\n",
    "        epsilon = 10e-8\n",
    "        return np.sum(-target*np.log(a2+epsilon)-(1-target)*np.log(1-a2+epsilon))\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        # assumes samples are given as columns\n",
    "        X = data.transpose()\n",
    "        X_norm = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "        return X_norm.transpose()\n",
    "    \n",
    "    def is_converged(self, old_weights, old_biases, new_weights, new_biases, threshold=0.01) -> bool:\n",
    "        max_relative_change = 0\n",
    "        epsilon = 10e-6\n",
    "        for key, val in old_weights.items():\n",
    "            rel_changes_w = np.max(np.absolute(new_weights[key] - old_weights[key])/(old_weights[key]+epsilon))\n",
    "            rel_changes_b = np.max(np.absolute(new_biases[key] - old_biases[key])/(old_biases[key]+epsilon))\n",
    "            max_relative_change = max(max_relative_change, rel_changes_w, rel_changes_b)\n",
    "        return max_relative_change < threshold\n",
    "    \n",
    "    # WX + B, where each column of X is a sample\n",
    "    def forward(self, data):\n",
    "        self.data = data.transpose()\n",
    "        self.data = self.normalize(self.data)  # normalize\n",
    "        self.z1 = np.dot(self.weights.get('L1'), self.data) + self.biases.get('L1')\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.a1 = self.normalize(self.a1)  # normalize\n",
    "        self.z2 = np.dot(self.weights.get('L2'), self.a1) + self.biases.get('L2')\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "#         print('a2 shape:',self.a2.shape)\n",
    "        return self.a2\n",
    "        \n",
    "    \n",
    "    def MSE(self, data, target):\n",
    "        return np.mean((self.forward(data) - target)**2)\n",
    "    \n",
    "    def backprop(self, a2, target):\n",
    "        new_weights = dict()\n",
    "        new_biases = dict()\n",
    "        \n",
    "        num_samples = a2.shape[1]\n",
    "#         print('num_samples',num_samples)\n",
    "#         print('a2:',a2.shape)\n",
    "#         print('target:',target.shape)\n",
    "        dJda2 = self.crossEntropyPrime(a2, target)\n",
    "#         print('dJda2:',dJda2.shape)\n",
    "        da2dz2 = self.sigmoidPrime(a2)\n",
    "#         print('da2dz2:',da2dz2.shape)\n",
    "        dJdz2 = dJda2 * da2dz2  # delta last layer\n",
    "#         print('dJdz2:',dJdz2.shape)\n",
    "        dz2dW2 = self.a2.transpose()\n",
    "#         print('dz2dW2:',dz2dW2.shape)\n",
    "        regularization_2 = self.regularization*self.weights['L2']\n",
    "        dJdW2 = np.dot(dJdz2, dz2dW2) + regularization_2\n",
    "#         print('dJdW2:',dJdW2.shape)\n",
    "\n",
    "    \n",
    "        # update W2, b2\n",
    "        new_weights['L2'] = self.weights['L2'] - self.learning_rate*dJdW2/num_samples\n",
    "        new_biases['L2'] = self.biases['L2'] - self.learning_rate*np.sum(dJdz2, axis=1)/num_samples\n",
    "#         print('bias shape after', new_biases['L2'])\n",
    "        \n",
    "        dJda1 = np.dot(self.weights['L2'].transpose(), dJdz2)\n",
    "        dJdz1 = self.sigmoidPrime(self.z1)\n",
    "        dJdz1 = dJda1*dJdz1  # delta hidden layer\n",
    "        regularization_1 = self.regularization*self.weights['L1']\n",
    "#         print('dJdz1 shape:',dJdz1.shape)\n",
    "        dJdW1 = np.dot(dJdz1, self.data.transpose()) + regularization_1\n",
    "\n",
    "    \n",
    "#         print('layer 1')\n",
    "#         print('delta sum shape',np.sum(dJdz1, axis=1).shape)\n",
    "#         print('bias shape before',self.biases['L1'])\n",
    "        \n",
    "        # update W1, b1\n",
    "        new_weights['L1'] = self.weights['L1'] - self.learning_rate*dJdW1/num_samples\n",
    "        new_biases['L1'] = self.biases['L1'] - self.learning_rate*np.sum(dJdz1, axis=1).reshape((dJdz1.shape[0],1))/num_samples\n",
    "#         print('bias shape after', new_biases['L1'])\n",
    "        \n",
    "        return new_weights, new_biases\n",
    "        \n",
    "        \n",
    "    def train(self, data, target, epochs=5, batch_size=10):\n",
    "        num_batches = np.ceil(data.shape[0]/batch_size)\n",
    "        x_batches = np.array_split(data, num_batches)\n",
    "        t_batches = np.array_split(target, num_batches, axis=1)\n",
    "        # stopping condition < 1% change\n",
    "        stop_thrsh = 0.0002\n",
    "        converged = False\n",
    "        for i in range(epochs):\n",
    "#             print('epoch:',i)\n",
    "\n",
    "            for j, batch in enumerate(x_batches):\n",
    "#                 print('batch:',j)\n",
    "#                 if i == 12 and j == 27:\n",
    "#                     print('weights:')\n",
    "#                     print(weights)\n",
    "#                     print('biases:')\n",
    "#                     print(biases)\n",
    "#                 print('forward')\n",
    "                a2 = self.forward(batch)\n",
    "#                 print('backward')\n",
    "                weights, biases = self.backprop(a2, t_batches[j])\n",
    "                # check convergence\n",
    "                converged = self.is_converged(self.weights, self.biases, weights, biases, stop_thrsh)\n",
    "                if converged:\n",
    "                    break\n",
    "                \n",
    "                self.weights = weights\n",
    "                self.biases = biases\n",
    "    #             print('epoch',i)\n",
    "    #             print('weights:')\n",
    "    #             print(self.weights)\n",
    "    #             print('biases:')\n",
    "    #             print(self.biases)\n",
    "            # check convergence\n",
    "            if converged:\n",
    "                break\n",
    "            a2 = self.forward(data)\n",
    "            print('mean cross entropy error:', self.crossEntropyError(a2, target)/a2.shape[1])\n",
    "            print('L2 weights:', self.weights['L2'])\n",
    "#         print(self.weights)\n",
    "#         print(self.biases)\n",
    "        return None\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross entropy error: 1.3919377919326879\n",
      "mean cross entropy error: 1.3744573063513847\n",
      "mean cross entropy error: 1.3578751930700232\n",
      "mean cross entropy error: 1.342113794118843\n",
      "mean cross entropy error: 1.3271048698146937\n",
      "{'L2': array([[0.39019367, 0.4188895 , 0.379056  ]]), 'L1': array([[0.20584178, 0.25366756],\n",
      "       [0.02314041, 0.79365522],\n",
      "       [0.27452474, 0.69370368]])}\n",
      "{'L2': array([[0.84405153]]), 'L1': array([[0.52164269],\n",
      "       [0.4219409 ],\n",
      "       [0.90372831]])}\n"
     ]
    }
   ],
   "source": [
    "model = NNModel(2,3,0.01)\n",
    "data = np.array([[1,3],[2,4],[3,1],[4,1]])\n",
    "targets = np.array([[0,0,1,1]])\n",
    "model.train(data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 0]]), array([[1]]), array([[1]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split(data, 3)\n",
    "np.array_split(targets, 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(767, 8)\n",
      "(1, 767)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.txt')\n",
    "df.head()\n",
    "X = df.iloc[:,:-1].values\n",
    "y = np.array([df.iloc[:,-1].values])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
      "  3.100e+01]\n",
      " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
      "  3.200e+01]\n",
      " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]\n",
      " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
      "  3.000e+01]\n",
      " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
      "  2.600e+01]\n",
      " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
      "  2.900e+01]\n",
      " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
      "  5.300e+01]\n",
      " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
      "  5.400e+01]\n",
      " [4.000e+00 1.100e+02 9.200e+01 0.000e+00 0.000e+00 3.760e+01 1.910e-01\n",
      "  3.000e+01]]\n",
      "[0 1 0 1 0 1 0 1 1 0]\n",
      "[[1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
      "  3.100e+01]\n",
      " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
      "  3.200e+01]\n",
      " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]\n",
      " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
      "  3.000e+01]\n",
      " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
      "  2.600e+01]\n",
      " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
      "  2.900e+01]\n",
      " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
      "  5.300e+01]]\n",
      "[[0 1 0 1 0 1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])\n",
    "print(y[0][:10])\n",
    "print(np.array_split(X,100)[0])\n",
    "print(np.array_split(y,80,axis=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross entropy error: 0.7175027298137092\n",
      "L2 weights: [[ 0.48451598  0.11555915 -0.1439925  -0.11371988  0.24927041  0.2251468\n",
      "   0.22179052 -0.11382516  0.47800752  0.30416694]]\n",
      "mean cross entropy error: 0.6670588393219025\n",
      "L2 weights: [[ 0.38302037  0.0545022  -0.17660189 -0.14964723  0.17355835  0.15207875\n",
      "   0.14909033 -0.14974097  0.37722526  0.22243807]]\n",
      "mean cross entropy error: 0.6660758294502231\n",
      "L2 weights: [[ 0.309982    0.0174703  -0.18830416 -0.1643038   0.12347758  0.1043522\n",
      "   0.10169132 -0.16438726  0.30482204  0.16699995]]\n",
      "mean cross entropy error: 0.6861823140913532\n",
      "L2 weights: [[ 0.25068221 -0.00976942 -0.19299044 -0.17162059  0.08461918  0.06758999\n",
      "   0.06522075 -0.1716949   0.2460878   0.12337138]]\n",
      "mean cross entropy error: 0.7188525409722354\n",
      "L2 weights: [[ 0.19974197 -0.03216346 -0.19530296 -0.1762753   0.05187989  0.03671715\n",
      "   0.03460758 -0.17634147  0.19565112  0.08638475]]\n",
      "mean cross entropy error: 0.7614389911370003\n",
      "L2 weights: [[ 0.15425006 -0.05223791 -0.19749689 -0.18055471  0.02259406  0.0090932\n",
      "   0.00721484 -0.18061363  0.15060757  0.05331709]]\n",
      "mean cross entropy error: 0.8143573496913932\n",
      "L2 weights: [[ 0.11211455 -0.07174178 -0.20107998 -0.18599471 -0.0051116  -0.01713273\n",
      "  -0.01880521 -0.18604718  0.10887129  0.02224411]]\n",
      "mean cross entropy error: 0.8810213929871189\n",
      "L2 weights: [[ 0.07131425 -0.09239093 -0.20755332 -0.19412144 -0.0330636  -0.04376718\n",
      "  -0.04525635 -0.19416815  0.06842646 -0.00870615]]\n",
      "mean cross entropy error: 0.9702468085127247\n",
      "L2 weights: [[ 0.02907865 -0.116684   -0.21922428 -0.20726456 -0.0638591  -0.07338954\n",
      "  -0.07471549 -0.20730616  0.02650738 -0.04217129]]\n",
      "mean cross entropy error: 1.1063770452596584\n",
      "L2 weights: [[-0.02035081 -0.15013748 -0.24143907 -0.23079017 -0.10310233 -0.11158821\n",
      "  -0.11276884 -0.2308272  -0.02264027 -0.08379157]]\n",
      "mean cross entropy error: 1.397552899041934\n",
      "L2 weights: [[-0.09975069 -0.21531239 -0.29660708 -0.28712533 -0.17343242 -0.18098823\n",
      "  -0.18203946 -0.28715831 -0.10178922 -0.15623817]]\n",
      "mean cross entropy error: 1.4814977765026762\n",
      "L2 weights: [[-0.53966813 -0.64256396 -0.71494853 -0.70650601 -0.60527414 -0.61200181\n",
      "  -0.61293782 -0.70653536 -0.54148323 -0.58996443]]\n",
      "mean cross entropy error: 0.8705510853304081\n",
      "L2 weights: [[-0.55812412 -0.64974229 -0.71419331 -0.70667611 -0.61653954 -0.62252983\n",
      "  -0.62336326 -0.70670226 -0.55974028 -0.60290781]]\n",
      "mean cross entropy error: 0.7289345582883505\n",
      "L2 weights: [[-0.53264301 -0.61421958 -0.6716066  -0.66491331 -0.58465594 -0.58998969\n",
      "  -0.59073176 -0.66493659 -0.53408204 -0.57251829]]\n",
      "mean cross entropy error: 0.662326847653875\n",
      "L2 weights: [[-0.50084934 -0.5734849  -0.62458214 -0.61862245 -0.54716151 -0.55191066\n",
      "  -0.55257141 -0.61864318 -0.50213064 -0.53635418]]\n",
      "mean cross entropy error: 0.6249895552026429\n",
      "L2 weights: [[-0.46846652 -0.53314103 -0.57863788 -0.57333139 -0.50970276 -0.51393139\n",
      "  -0.51451972 -0.57334984 -0.46960739 -0.50007994]]\n",
      "mean cross entropy error: 0.601389128148099\n",
      "L2 weights: [[-0.43719724 -0.49478325 -0.53529352 -0.53056864 -0.47391388 -0.47767904\n",
      "  -0.47820288 -0.53058507 -0.43821307 -0.46534574]]\n",
      "mean cross entropy error: 0.5850670045562628\n",
      "L2 weights: [[-0.40758857 -0.458863   -0.49493324 -0.49072621 -0.44028096 -0.44363345\n",
      "  -0.44409988 -0.49074084 -0.40849306 -0.43265192]]\n",
      "mean cross entropy error: 0.5730019179983111\n",
      "L2 weights: [[-0.37977573 -0.42543034 -0.45754718 -0.45380126 -0.40888495 -0.41187\n",
      "  -0.4122853  -0.45381428 -0.38058108 -0.40209207]]\n",
      "mean cross entropy error: 0.5636496669342994\n",
      "L2 weights: [[-0.35373577 -0.39438651 -0.42298326 -0.4196479  -0.37965454 -0.38231242\n",
      "  -0.3826822  -0.4196595  -0.35445285 -0.37360617]]\n",
      "mean cross entropy error: 0.5561616669774274\n",
      "L2 weights: [[-0.32938545 -0.36558076 -0.39104323 -0.38807344 -0.35246346 -0.35483002\n",
      "  -0.35515928 -0.38808377 -0.33002394 -0.34707801]]\n",
      "mean cross entropy error: 0.5500417643607375\n",
      "L2 weights: [[-0.30662119 -0.3388494  -0.36152112 -0.35887682 -0.32716978 -0.32927697\n",
      "  -0.32957014 -0.35888601 -0.30718971 -0.3223746 ]]\n",
      "mean cross entropy error: 0.5449835894597483\n",
      "L2 weights: [[-0.28533565 -0.31403156 -0.3342184  -0.33186392 -0.30363206 -0.3055083\n",
      "  -0.30576933 -0.33187211 -0.28584185 -0.29936244]]\n",
      "mean cross entropy error: 0.5407884961500062\n",
      "L2 weights: [[-0.2654246  -0.29097536 -0.30894966 -0.30685324 -0.28171567 -0.28338626\n",
      "  -0.28361869 -0.30686053 -0.26587532 -0.27791401]]\n",
      "mean cross entropy error: 0.5373218816509174\n",
      "L2 weights: [[-0.24678961 -0.26953994 -0.28554421 -0.28367756 -0.26129514 -0.26278263\n",
      "  -0.26298958 -0.28368405 -0.24719093 -0.25791015]]\n",
      "mean cross entropy error: 0.5344887868453357\n",
      "L2 weights: [[-0.2293391  -0.24959593 -0.26384609 -0.26218403 -0.24225478 -0.24357924\n",
      "  -0.24376351 -0.26218981 -0.22969643 -0.2392408 ]]\n",
      "mean cross entropy error: 0.5322196246069377\n",
      "L2 weights: [[-0.21298853 -0.23102516 -0.24371346 -0.24223357 -0.22448862 -0.22566792\n",
      "  -0.22583199 -0.24223872 -0.2133067  -0.22180498]]\n",
      "mean cross entropy error: 0.530461445856294\n",
      "L2 weights: [[-0.19766045 -0.21372022 -0.22501785 -0.22370016 -0.2079001  -0.20895014\n",
      "  -0.20909623 -0.22370474 -0.19794375 -0.20551059]]\n",
      "mean cross entropy error: 0.5291723760199469\n",
      "L2 weights: [[-0.18328423 -0.1975838  -0.20764318 -0.20646991 -0.19240158 -0.19333654\n",
      "  -0.19346661 -0.20647399 -0.18353647 -0.19027397]]\n",
      "mean cross entropy error: 0.528318013412593\n",
      "L2 weights: [[-0.16979573 -0.18252803 -0.19148488 -0.1904402  -0.1779138  -0.17874628\n",
      "  -0.1788621  -0.19044384 -0.17002033 -0.17601938]]\n",
      "mean cross entropy error: 0.5278692351019738\n",
      "L2 weights: [[-0.1571369  -0.1684737  -0.17644886 -0.17551868 -0.16436521 -0.16510644\n",
      "  -0.16520957 -0.17552191 -0.15733688 -0.16267842]]\n",
      "mean cross entropy error: 0.5278012511847743\n",
      "L2 weights: [[-0.14525518 -0.15534944 -0.16245049 -0.16162227 -0.15169124 -0.15235124\n",
      "  -0.15244306 -0.16162515 -0.14543324 -0.15018933]]\n",
      "mean cross entropy error: 0.528093972850393\n",
      "L2 weights: [[-0.13410298 -0.14309088 -0.14941364 -0.14867619 -0.13983363 -0.14042129\n",
      "  -0.14050305 -0.14867875 -0.13426153 -0.13849634]]\n",
      "mean cross entropy error: 0.5287337902851393\n",
      "L2 weights: [[-0.12363704 -0.13163984 -0.13726961 -0.13661298 -0.1287396  -0.12926284\n",
      "  -0.12933564 -0.13661527 -0.12377821 -0.12754887]]\n",
      "mean cross entropy error: 0.5297165818943363\n",
      "L2 weights: [[-0.11381773 -0.12094341 -0.12595614 -0.12537148 -0.11836104 -0.11882694\n",
      "  -0.11889176 -0.12537352 -0.11394343 -0.11730082]]\n",
      "mean cross entropy error: 0.5310511023182156\n",
      "L2 weights: [[-0.10460842 -0.1109531  -0.11541642 -0.11489585 -0.10865377 -0.1090686\n",
      "  -0.10912632 -0.11489766 -0.10472034 -0.10770975]]\n",
      "mean cross entropy error: 0.5327610170613729\n",
      "L2 weights: [[-0.09597487 -0.10162416 -0.10559829 -0.10513477 -0.09957684 -0.09994621\n",
      "  -0.0999976  -0.10513638 -0.09607453 -0.09873629]]\n",
      "mean cross entropy error: 0.5348834736511778\n",
      "L2 weights: [[-0.08788504 -0.09291515 -0.0964537  -0.09604098 -0.09109222 -0.0914211\n",
      "  -0.09146686 -0.09604242 -0.08797377 -0.0903438 ]]\n",
      "mean cross entropy error: 0.5374631249979385\n",
      "L2 weights: [[-0.08030886 -0.08478765 -0.08793837 -0.08757089 -0.08316452 -0.08345736\n",
      "  -0.0834981  -0.08757217 -0.08038786 -0.08249813]]\n",
      "mean cross entropy error: 0.5405427035287713\n",
      "L2 weights: [[-0.07321819 -0.0772061  -0.08001149 -0.07968429 -0.07576087 -0.07602161\n",
      "  -0.07605789 -0.07968543 -0.07328854 -0.07516751]]\n",
      "cross entropy error: 2933.4933499744175\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "pid_model = NNModel(8,10,0.003)\n",
    "pid_model.train(X,y,40)\n",
    "pred = pid_model.forward(X) > 0.5\n",
    "print('cross entropy error:',pid_model.crossEntropyError(pred, y))\n",
    "# print('accuracy:', (y==pred)/len(y[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7627118644067796\n"
     ]
    }
   ],
   "source": [
    "# print(y)\n",
    "# print(pred)\n",
    "print(np.sum(y==pred)/len(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max values: [ 17.   199.   122.    99.   846.    67.1    2.42  81.  ]\n",
      "min values: [ 0.     0.     0.     0.     0.     0.     0.078 21.   ]\n",
      "[  3.36867837  31.9576152   19.35552462  15.94365537 115.20792869\n",
      "   7.8839464    0.33128119  11.74463189]\n",
      "[  3.8422425  120.85919166  69.10169492  20.51760104  79.90352021\n",
      "  31.9904824    0.47167405  33.2190352 ]\n",
      "[[-0.84372629 -1.12208597 -0.16024856 ... -0.68372895 -0.36426474\n",
      "  -0.18894038]\n",
      " [ 1.23423997  1.94447577 -0.26357823 ... -1.10230105  0.60470064\n",
      "  -0.1037951 ]\n",
      " [-0.84372629 -0.99692019 -0.16024856 ... -0.49346891 -0.91968415\n",
      "  -1.0403932 ]\n",
      " ...\n",
      " [ 0.343683    0.0044061   0.14974046 ... -0.73446496 -0.68423462\n",
      "  -0.27408566]\n",
      " [-0.84372629  0.16086333 -0.47023757 ... -0.23978884 -0.37030191\n",
      "   1.17338414]\n",
      " [-0.84372629 -0.8717544   0.04641078 ... -0.20173684 -0.47293375\n",
      "  -0.87010264]]\n"
     ]
    }
   ],
   "source": [
    "# trying to standardize the data\n",
    "print('max values:',X.max(axis=0))\n",
    "print('min values:',X.min(axis=0))\n",
    "print(X.std(axis=0))\n",
    "print(X.mean(axis=0))\n",
    "X_norm = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "print(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "767/767 [==============================] - 1s 799us/step - loss: 0.6507 - acc: 0.6519\n",
      "Epoch 2/20\n",
      "767/767 [==============================] - 0s 145us/step - loss: 0.6428 - acc: 0.6519\n",
      "Epoch 3/20\n",
      "767/767 [==============================] - 0s 167us/step - loss: 0.6401 - acc: 0.6519\n",
      "Epoch 4/20\n",
      "767/767 [==============================] - 0s 150us/step - loss: 0.6378 - acc: 0.6506\n",
      "Epoch 5/20\n",
      "767/767 [==============================] - 0s 154us/step - loss: 0.6328 - acc: 0.6519\n",
      "Epoch 6/20\n",
      "767/767 [==============================] - 0s 145us/step - loss: 0.6295 - acc: 0.6519\n",
      "Epoch 7/20\n",
      "767/767 [==============================] - 0s 171us/step - loss: 0.6267 - acc: 0.6532\n",
      "Epoch 8/20\n",
      "767/767 [==============================] - 0s 146us/step - loss: 0.6233 - acc: 0.6532\n",
      "Epoch 9/20\n",
      "767/767 [==============================] - 0s 142us/step - loss: 0.6205 - acc: 0.6519\n",
      "Epoch 10/20\n",
      "767/767 [==============================] - 0s 150us/step - loss: 0.6170 - acc: 0.6532\n",
      "Epoch 11/20\n",
      "767/767 [==============================] - 0s 136us/step - loss: 0.6140 - acc: 0.6506\n",
      "Epoch 12/20\n",
      "767/767 [==============================] - 0s 141us/step - loss: 0.6122 - acc: 0.6519\n",
      "Epoch 13/20\n",
      "767/767 [==============================] - 0s 145us/step - loss: 0.6102 - acc: 0.6519\n",
      "Epoch 14/20\n",
      "767/767 [==============================] - 0s 134us/step - loss: 0.6072 - acc: 0.6519\n",
      "Epoch 15/20\n",
      "767/767 [==============================] - 0s 151us/step - loss: 0.6063 - acc: 0.6532\n",
      "Epoch 16/20\n",
      "767/767 [==============================] - 0s 135us/step - loss: 0.6055 - acc: 0.6545\n",
      "Epoch 17/20\n",
      "767/767 [==============================] - 0s 145us/step - loss: 0.6015 - acc: 0.6610\n",
      "Epoch 18/20\n",
      "767/767 [==============================] - 0s 154us/step - loss: 0.6005 - acc: 0.6571\n",
      "Epoch 19/20\n",
      "767/767 [==============================] - 0s 143us/step - loss: 0.5990 - acc: 0.6597\n",
      "Epoch 20/20\n",
      "767/767 [==============================] - 0s 136us/step - loss: 0.5960 - acc: 0.6597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "390251.22928100824"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check performance of Keras network\n",
    "# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "# https://keras.io/api/optimizers/\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "model.fit(X,y.reshape(len(y[0]),-1), epochs = 20, batch_size=10)\n",
    "preds = model.predict(X)\n",
    "pid_model.crossEntropyError(preds, y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
